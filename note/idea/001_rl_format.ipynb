{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerer la format de sortie de l'apprentissage par renforcement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input of the RL system is a wavelet series of the regidual error comme the state vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the original quantum circuit is written as the folloing:\n",
    "$$\n",
    "\\Sigma_\\ell = \\underset{j \\in J}{\\otimes} \\Sigma_{\\ell j} \\longleftarrow a_\\ell = \\left< \\: g_\\ell, \\; q_\\ell \\: \\right> \\longleftarrow \\pi\\left( s_\\ell ; \\; \\phi \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State consists the partial wavelet series of the residual error vector:\n",
    "$$\n",
    "s_\\ell = F_w \\left( \\varepsilon_\\ell; \\; \\omega \\right) \\\\\n",
    "\n",
    "\\varepsilon_\\ell = \\left[ \\: t_k - \\left< \\: B \\rho_\\ell \\left( x_k; \\; \\theta_L \\right) \\: \\right> | \\; \\forall \\left( x_k, t_k \\right) \\in \\mathcal{D} \\: \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qml.model.gate import Gateset\n",
    "from qml.model.unit import UnitManager, Unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 2\n",
    "num_gates = 3\n",
    "dim_wavelet = 4\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "beta = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 18])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Policy(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_wavelet: int, num_qubits: int, num_gates: int, dim_hiddens: list[int] = [32, 32]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.nq = num_qubits\n",
    "        self.ng = num_gates\n",
    "        gset = Gateset.set_num_qubits(num_qubits)\n",
    "\n",
    "        self.dim_gateinfo = gset.size * self.ng\n",
    "        self.dim_qubitinfo = self.ng * self.nq\n",
    "        self.dim_output = dim_output = self.dim_gateinfo + self.dim_qubitinfo\n",
    "        self.dim_input = dim_input = 2 ** dim_wavelet - 1\n",
    "\n",
    "        dim_units = dim_hiddens.copy()\n",
    "        dim_units.append(dim_output)\n",
    "        dim_units.insert(0, dim_input)\n",
    "        self.net = nn.Sequential(\n",
    "            *sum([\n",
    "                self.build_layer(din, dout, activation=(l < len(dim_hiddens)))\n",
    "                for l, din, dout in zip(range(len(dim_units)+1), dim_units[:-1], dim_units[1:]) \n",
    "            ], [])\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_layer(din, dout, activation=True):\n",
    "        layer = [nn.Linear(din, dout)]\n",
    "        if activation:\n",
    "            layer.append(nn.ReLU())\n",
    "        return layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feat = self.net(x)\n",
    "        return feat\n",
    "\n",
    "\n",
    "actor = Policy(dim_wavelet, num_qubits, num_gates)\n",
    "xs = torch.from_numpy(np.random.rand(batch_size, 2**dim_wavelet-1)).float()\n",
    "act_features = actor(xs)\n",
    "act_features.shape\n",
    "# act_features = act_features.view(-1, 2, num_gates)\n",
    "# actions = torch.argmax(act_features, dim=-1)\n",
    "# print(act_features)\n",
    "# print(actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prob_table(logits: torch.Tensor, num_gates: int):\n",
    "    logits = logits.reshape(num_gates, -1)\n",
    "    probs = torch.softmax(logits, 1)\n",
    "    return probs\n",
    "\n",
    "def select_idx_at_prob(probs: torch.Tensor):\n",
    "    np_probs = probs.detach().numpy()\n",
    "    size = np_probs.shape[1]\n",
    "    selectables = np.arange(size)\n",
    "    idxs = np.array([\n",
    "        np.random.choice(selectables, replace=True, p=prob)\n",
    "        for prob in np_probs\n",
    "    ])\n",
    "    return idxs\n",
    "\n",
    "def get_onehot(idx, num_classes):\n",
    "    onehot = nn.functional.one_hot(torch.from_numpy(idx), num_classes)\n",
    "    return onehot\n",
    "\n",
    "def calc_selected_probs(probs, onehot):\n",
    "    filtered = probs * onehot\n",
    "    probs = filtered.sum(1)\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_candidates = 5\n",
    "\n",
    "batch_size = 4\n",
    "len_wavelet_series = 2 ** dim_wavelet - 1\n",
    "gset = Gateset.set_num_qubits(num_qubits)\n",
    "\n",
    "dim_gateinfo = gset.size * num_gates\n",
    "\n",
    "uman = UnitManager(num_qubits, num_gates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare models\n",
    "policy = Policy(dim_wavelet, num_qubits, num_gates)\n",
    "policy_ref = Policy(dim_wavelet, num_qubits, num_gates)\n",
    "policy_ref.load_state_dict(policy.state_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with buffer\n",
    "- wavelet seriese\n",
    "- list[unit json]\n",
    "- list[loss]\n",
    "\n",
    "1. predict prob table\n",
    "2. calc probs for units\n",
    "3. calc loss of DPO\n",
    "3. training step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RX': 0, 'RY': 1, 'RZ': 2, 'CZ': 3}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdict = {key: i for i, key in enumerate(gset.keys())}\n",
    "gdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13829247 0.69440971 0.12206243 0.09769475 0.42599988]\n"
     ]
    }
   ],
   "source": [
    "# wavelet series\n",
    "states = np.random.rand(2 ** dim_wavelet - 1)\n",
    "\n",
    "# unit json\n",
    "units = [uman.generate_random_unit() for _ in range(num_candidates)]\n",
    "ujsons = [unit.to_json() for unit in units]\n",
    "\n",
    "# losses for each unit\n",
    "losses = np.random.rand(num_candidates)\n",
    "print(losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW data gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_data():\n",
    "    states = np.random.rand(2 ** dim_wavelet - 1)\n",
    "    udicts = [unit.to_dict() for unit in units]\n",
    "    losses = np.random.rand(num_candidates)\n",
    "    return states, udicts, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_db_json(pwseriese, udicts, losses):\n",
    "    if isinstance(pwseriese, np.ndarray):\n",
    "        pwseriese = pwseriese.tolist()\n",
    "    if isinstance(udicts[0], Unit):\n",
    "        udicts = [unit.to_dict() for unit in units]\n",
    "    if isinstance(losses, np.ndarray):\n",
    "        losses = losses.tolist()\n",
    "    data = dict(\n",
    "        pwseries=pwseriese,\n",
    "        units=udicts,\n",
    "        losses=losses,\n",
    "    )\n",
    "    djson = json.dumps(data)\n",
    "    return djson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"pwseries\": [0.5610219497431205, 0.4248068396481297, 0.32671685122822425, 0.005159735984395897, 0.5024070739362936, 0.10545909912556395, 0.17577469853905225, 0.49217431117780874, 0.053339417202042605, 0.2658375751933949, 0.35820264999165874, 0.3539492500895648, 0.8988563619370747, 0.024339032191310617, 0.973204539282582], \"units\": [{\"name\": \"unit_15\", \"gates\": [\"cz\", \"ry\", \"cz\"], \"qubits\": [1, 0, 0], \"params\": [0.0]}, {\"name\": \"unit_16\", \"gates\": [\"rx\", \"rx\", \"rz\"], \"qubits\": [1, 0, 0], \"params\": [0.0, 0.0, 0.0]}, {\"name\": \"unit_17\", \"gates\": [\"rz\", \"rz\", \"cz\"], \"qubits\": [1, 0, 1], \"params\": [0.0, 0.0]}, {\"name\": \"unit_18\", \"gates\": [\"rx\", \"rx\", \"ry\"], \"qubits\": [1, 0, 0], \"params\": [0.0, 0.0, 0.0]}, {\"name\": \"unit_19\", \"gates\": [\"rx\", \"rz\", \"cz\"], \"qubits\": [0, 0, 1], \"params\": [0.0, 0.0]}], \"losses\": [0.1648565772331949, 0.027398155840465788, 0.7185280222624457, 0.12626717648477725, 0.7594827934668941]}'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "djson = make_db_json(states, units, losses)\n",
    "djson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pwseries': [0.5610219497431205,\n",
       "  0.4248068396481297,\n",
       "  0.32671685122822425,\n",
       "  0.005159735984395897,\n",
       "  0.5024070739362936,\n",
       "  0.10545909912556395,\n",
       "  0.17577469853905225,\n",
       "  0.49217431117780874,\n",
       "  0.053339417202042605,\n",
       "  0.2658375751933949,\n",
       "  0.35820264999165874,\n",
       "  0.3539492500895648,\n",
       "  0.8988563619370747,\n",
       "  0.024339032191310617,\n",
       "  0.973204539282582],\n",
       " 'units': [{'name': 'unit_15',\n",
       "   'gates': ['cz', 'ry', 'cz'],\n",
       "   'qubits': [1, 0, 0],\n",
       "   'params': [0.0]},\n",
       "  {'name': 'unit_16',\n",
       "   'gates': ['rx', 'rx', 'rz'],\n",
       "   'qubits': [1, 0, 0],\n",
       "   'params': [0.0, 0.0, 0.0]},\n",
       "  {'name': 'unit_17',\n",
       "   'gates': ['rz', 'rz', 'cz'],\n",
       "   'qubits': [1, 0, 1],\n",
       "   'params': [0.0, 0.0]},\n",
       "  {'name': 'unit_18',\n",
       "   'gates': ['rx', 'rx', 'ry'],\n",
       "   'qubits': [1, 0, 0],\n",
       "   'params': [0.0, 0.0, 0.0]},\n",
       "  {'name': 'unit_19',\n",
       "   'gates': ['rx', 'rz', 'cz'],\n",
       "   'qubits': [0, 0, 1],\n",
       "   'params': [0.0, 0.0]}],\n",
       " 'losses': [0.1648565772331949,\n",
       "  0.027398155840465788,\n",
       "  0.7185280222624457,\n",
       "  0.12626717648477725,\n",
       "  0.7594827934668941]}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdata = json.loads(djson)\n",
    "rdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_gate_indices(udicts):\n",
    "    # convert json to indices\n",
    "    # 1 gates\n",
    "    sgates = [uinfo[\"gates\"] for uinfo in udicts]\n",
    "    igates = [\n",
    "        [gdict[sg.upper()] for sg in sgate]\n",
    "        for sgate in sgates\n",
    "    ]\n",
    "    return igates\n",
    "\n",
    "def decode_qubits(udicts):\n",
    "    # 2 qubits\n",
    "    iqubits = [uinfo[\"qubits\"] for uinfo in udicts]\n",
    "    \n",
    "    return iqubits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[3, 1, 3], [0, 0, 2], [2, 2, 3], [0, 0, 1], [0, 2, 3]],\n",
       " [[1, 0, 0], [1, 0, 0], [1, 0, 1], [1, 0, 0], [0, 0, 1]])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_udicts(rdata[\"units\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(rdata[\"pwseries\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consider le batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchData:\n",
    "\n",
    "    def __init__(self, pwserieses, gate_indices, qubits, losses, num_gate_classes, num_qubits):\n",
    "        self._pwserieses = np.asarray(pwserieses)\n",
    "        self._gate_indices = np.asarray(gate_indices)\n",
    "        self._qubits = np.asarray(qubits)\n",
    "        self._losses = np.asarray(losses)\n",
    "        self.size = len(qubits)\n",
    "        self.num_gate_classes = num_gate_classes\n",
    "        self.num_qubits = num_qubits\n",
    "        self.num_cadicates = self.losses.shape[-1]\n",
    "    \n",
    "    @property\n",
    "    def pwserieses(self):\n",
    "        return torch.from_numpy(self._pwserieses).float()\n",
    "    @property\n",
    "    def states(self):\n",
    "        return self.pwserieses\n",
    "    @property\n",
    "    def np_pwserieses(self):\n",
    "        return self._pwserieses.copy()\n",
    "    \n",
    "    @property\n",
    "    def gate_indices(self):\n",
    "        return torch.from_numpy(self._gate_indices).float()\n",
    "    @property\n",
    "    def igates(self):\n",
    "        return self.gate_indices\n",
    "    @property\n",
    "    def np_gate_indices(self):\n",
    "        return self._gate_indices.copy()\n",
    "    @property\n",
    "    def onehot_igates(self):\n",
    "        return get_onehot(self._gate_indices, self.num_gate_classes)\n",
    "    \n",
    "    @property\n",
    "    def qubits(self):\n",
    "        return torch.from_numpy(self._qubits).float()\n",
    "    @property\n",
    "    def np_qubits(self):\n",
    "        return self._qubits.copy()\n",
    "    @property\n",
    "    def onehot_qubits(self):\n",
    "        return get_onehot(self._qubits, self.num_qubits)\n",
    "    \n",
    "    @property\n",
    "    def losses(self):\n",
    "        return torch.from_numpy(self._losses).float()\n",
    "    @property\n",
    "    def np_losses(self):\n",
    "        return self._losses.copy()\n",
    "    @property\n",
    "    def best_indices(self):\n",
    "        return torch.argmin(self.losses, dim=-1)\n",
    "    @property\n",
    "    def onehot_ibests(self):\n",
    "        return get_onehot(np.argmin(self.np_losses, axis=-1), self.num_cadicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"pwseries\": [0.5660569355850306, 0.5801335132441083, 0.41876590896698174, 0.7757465754614421, 0.17146400948803642, 0.8249182098833542, 0.7029926606449767, 0.02850381134829305, 0.8216821751237374, 0.7469196735665115, 0.20055910903906726, 0.8503942063551014, 0.9675239400755534, 0.38901468536903605, 0.36128104384650805], \"units\": [{\"name\": \"unit_15\", \"gates\": [\"cz\", \"ry\", \"cz\"], \"qubits\": [1, 0, 0], \"params\": [0.0]}, {\"name\": \"unit_16\", \"gates\": [\"rx\", \"rx\", \"rz\"], \"qubits\": [1, 0, 0], \"params\": [0.0, 0.0, 0.0]}, {\"name\": \"unit_17\", \"gates\": [\"rz\", \"rz\", \"cz\"], \"qubits\": [1, 0, 1], \"params\": [0.0, 0.0]}, {\"name\": \"unit_18\", \"gates\": [\"rx\", \"rx\", \"ry\"], \"qubits\": [1, 0, 0], \"params\": [0.0, 0.0, 0.0]}, {\"name\": \"unit_19\", \"gates\": [\"rx\", \"rz\", \"cz\"], \"qubits\": [0, 0, 1], \"params\": [0.0, 0.0]}], \"losses\": [0.46741752904476186, 0.17349056878167646, 0.5966442677772882, 0.7614166474717902, 0.7162669422931702]}',\n",
       " '{\"pwseries\": [0.5519988502746666, 0.4644204501949948, 0.2041280407023356, 0.6937346030731455, 0.7953593833329808, 0.2108777528121233, 0.7281792441693359, 0.31890475897555526, 0.9227446656134489, 0.009989388352801498, 0.4740226478186299, 0.8648618267903161, 0.26170748855808446, 0.05524653997879336, 0.3664075108462814], \"units\": [{\"name\": \"unit_15\", \"gates\": [\"cz\", \"ry\", \"cz\"], \"qubits\": [1, 0, 0], \"params\": [0.0]}, {\"name\": \"unit_16\", \"gates\": [\"rx\", \"rx\", \"rz\"], \"qubits\": [1, 0, 0], \"params\": [0.0, 0.0, 0.0]}, {\"name\": \"unit_17\", \"gates\": [\"rz\", \"rz\", \"cz\"], \"qubits\": [1, 0, 1], \"params\": [0.0, 0.0]}, {\"name\": \"unit_18\", \"gates\": [\"rx\", \"rx\", \"ry\"], \"qubits\": [1, 0, 0], \"params\": [0.0, 0.0, 0.0]}, {\"name\": \"unit_19\", \"gates\": [\"rx\", \"rz\", \"cz\"], \"qubits\": [0, 0, 1], \"params\": [0.0, 0.0]}], \"losses\": [0.18932411558557538, 0.7043123192950945, 0.18974954890944018, 0.2754991556586761, 0.8803424938145954]}',\n",
       " '{\"pwseries\": [0.6353906581533486, 0.4542303570502213, 0.7797547245725461, 0.13700733844112112, 0.0731220932277531, 0.18557695334739055, 0.9846087968761079, 0.49984002085820967, 0.8090134558596477, 0.2901715985051201, 0.43507422468597645, 0.39915642109845584, 0.6141730351033855, 0.30960568896243557, 0.6446074903026231], \"units\": [{\"name\": \"unit_15\", \"gates\": [\"cz\", \"ry\", \"cz\"], \"qubits\": [1, 0, 0], \"params\": [0.0]}, {\"name\": \"unit_16\", \"gates\": [\"rx\", \"rx\", \"rz\"], \"qubits\": [1, 0, 0], \"params\": [0.0, 0.0, 0.0]}, {\"name\": \"unit_17\", \"gates\": [\"rz\", \"rz\", \"cz\"], \"qubits\": [1, 0, 1], \"params\": [0.0, 0.0]}, {\"name\": \"unit_18\", \"gates\": [\"rx\", \"rx\", \"ry\"], \"qubits\": [1, 0, 0], \"params\": [0.0, 0.0, 0.0]}, {\"name\": \"unit_19\", \"gates\": [\"rx\", \"rz\", \"cz\"], \"qubits\": [0, 0, 1], \"params\": [0.0, 0.0]}], \"losses\": [0.9665494784379252, 0.8847156859655971, 0.2389087437481079, 0.3728611237867059, 0.31774605894582875]}',\n",
       " '{\"pwseries\": [0.6226504399400141, 0.8793799701542674, 0.9697264007553936, 0.8370831144573628, 0.41969979883322717, 0.5254927705387635, 0.6462149094851726, 0.8976607604232922, 0.4744228924375177, 0.6905033055039873, 0.46388038179210467, 0.6769482733027525, 0.8365027244700636, 0.5226747844793145, 0.6623461102763855], \"units\": [{\"name\": \"unit_15\", \"gates\": [\"cz\", \"ry\", \"cz\"], \"qubits\": [1, 0, 0], \"params\": [0.0]}, {\"name\": \"unit_16\", \"gates\": [\"rx\", \"rx\", \"rz\"], \"qubits\": [1, 0, 0], \"params\": [0.0, 0.0, 0.0]}, {\"name\": \"unit_17\", \"gates\": [\"rz\", \"rz\", \"cz\"], \"qubits\": [1, 0, 1], \"params\": [0.0, 0.0]}, {\"name\": \"unit_18\", \"gates\": [\"rx\", \"rx\", \"ry\"], \"qubits\": [1, 0, 0], \"params\": [0.0, 0.0, 0.0]}, {\"name\": \"unit_19\", \"gates\": [\"rx\", \"rz\", \"cz\"], \"qubits\": [0, 0, 1], \"params\": [0.0, 0.0]}], \"losses\": [0.20993300979868224, 0.4800871889288407, 0.020841139613355875, 0.7499709557966102, 0.1887522057386205]}']"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_data = [\n",
    "    make_db_json(*generate_random_data())\n",
    "    for _ in range(batch_size)\n",
    "]\n",
    "batch_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = BatchData(\n",
    "    np.vstack([bd[\"pwseries\"] for bd in batch_dicts]),\n",
    "    [decode_gate_indices(bd[\"units\"]) for bd in batch_dicts],\n",
    "    [decode_qubits(bd[\"units\"]) for bd in batch_dicts],\n",
    "    np.vstack([bd[\"losses\"] for bd in batch_dicts]),\n",
    "    gset.size, num_qubits\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0027, 0.0028, 0.0013, 0.0031, 0.0014],\n",
      "        [0.0025, 0.0027, 0.0013, 0.0032, 0.0015],\n",
      "        [0.0025, 0.0026, 0.0013, 0.0029, 0.0014],\n",
      "        [0.0025, 0.0027, 0.0013, 0.0029, 0.0013]], grad_fn=<CatBackward0>)\n",
      "tensor([[0.0027, 0.0028, 0.0013, 0.0031, 0.0014],\n",
      "        [0.0025, 0.0027, 0.0013, 0.0032, 0.0015],\n",
      "        [0.0025, 0.0026, 0.0013, 0.0029, 0.0014],\n",
      "        [0.0025, 0.0027, 0.0013, 0.0029, 0.0013]])\n"
     ]
    }
   ],
   "source": [
    "def calc_selected_probs(logits, onehots, num_gates):\n",
    "    probs = calc_prob_table(logits, num_gates)\n",
    "    probs = probs.view(1, *probs.shape)\n",
    "    filtered_probs = probs * onehots\n",
    "    selected_probs = filtered_probs.sum(dim=-1)\n",
    "    return selected_probs\n",
    "\n",
    "def _calc_prob(gate_logits, qubit_logits, gate_onehot, qubit_onehot):\n",
    "    gate_selected_probs = calc_selected_probs(gate_logits, gate_onehot, policy.ng)\n",
    "    qubit_selected_probs = calc_selected_probs(qubit_logits, qubit_onehot, policy.ng)\n",
    "    selected_probs = gate_selected_probs * qubit_selected_probs\n",
    "    probs = selected_probs.prod(dim=1)\n",
    "    return probs\n",
    "\n",
    "def calc_probs(model, batch):\n",
    "    batch_logits = model(batch.states)\n",
    "    batch_gate_logits  = batch_logits[..., :policy.dim_gateinfo]\n",
    "    batch_qubit_logits = batch_logits[..., policy.dim_gateinfo:]\n",
    "\n",
    "    probs = torch.vstack([\n",
    "        _calc_prob(gate_logits, qubit_logits, gate_onehot, qubit_onehot)\n",
    "        for gate_logits, qubit_logits, gate_onehot, qubit_onehot\n",
    "        in zip(batch_gate_logits, batch_qubit_logits, batch.onehot_igates, batch.onehot_qubits)\n",
    "    ])\n",
    "    return probs\n",
    "\n",
    "probs = calc_probs(policy, batch)\n",
    "probs_ref = calc_probs(policy_ref, batch).detach()\n",
    "print(probs)\n",
    "print(probs_ref)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 3, 4])\n",
      "torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "print(batch.onehot_igates.shape)\n",
    "print(batch.best_indices.shape)\n",
    "# print(batch.best_indices.reshape(1, num_candidates, 1))\n",
    "# best_gate_indices = torch.gather(batch.onehot_igates, -1, )\n",
    "# best_gate_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = policy(batch.states)\n",
    "gate_logits = logits[..., :policy.dim_gateinfo]\n",
    "qbit_logits = logits[..., policy.dim_gateinfo:]\n",
    "\n",
    "rs_gate_logits = gate_logits.view(batch.size, policy.ng, -1)\n",
    "logp_gate = nn.functional.log_softmax(rs_gate_logits, dim=-1)\n",
    "\n",
    "rs_qbit_logits = qbit_logits.view(batch.size, policy.ng, -1)\n",
    "logp_qbit = nn.functional.log_softmax(rs_qbit_logits, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5, 3])\n",
      "torch.Size([4, 5, 3])\n",
      "torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "rs_logp_gate = logp_gate.unsqueeze(1)\n",
    "selected_logp_gate = (batch.onehot_igates * rs_logp_gate).sum(dim=-1)\n",
    "\n",
    "rs_logp_qbit = logp_qbit.unsqueeze(1)\n",
    "selected_logp_qbit = (batch.onehot_qubits * rs_logp_qbit).sum(dim=-1)\n",
    "\n",
    "selected_logp = (selected_logp_gate + selected_logp_qbit).sum(dim=-1)\n",
    "print(selected_logp_gate.shape)\n",
    "print(selected_logp_qbit.shape)\n",
    "print(selected_logp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.8862, -5.9920, -6.6633, -6.6659], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_logp = (batch.onehot_ibests * selected_logp).sum(dim=-1)\n",
    "best_logp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.2424, -6.2138, -6.0962, -6.1011], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_logp = (selected_logp.sum(dim=-1) - best_logp) / (num_candidates - 1)\n",
    "other_logp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-5.8899, -6.4940, -6.3668, -6.2932], grad_fn=<SumBackward1>),\n",
       " tensor([-6.2314, -6.1534, -6.1864, -6.1731], grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_logp(logits, num_gates):\n",
    "    rs_logits = logits.view(batch.size, num_gates, -1)\n",
    "    return nn.functional.log_softmax(rs_logits, dim=-1)\n",
    "\n",
    "def calc_selected_logp(logp, onehot):\n",
    "    rs_logp = logp.unsqueeze(1)\n",
    "    return (onehot * rs_logp).sum(dim=-1)\n",
    "\n",
    "\n",
    "def calc_logps(model, batch, num_candidates, num_gates, detach=False):\n",
    "    logits = model(batch.states)\n",
    "    logits_gate = logits[..., :model.dim_gateinfo]\n",
    "    logits_qbit = logits[..., model.dim_gateinfo:]\n",
    "\n",
    "    logp_gate = calc_logp(logits_gate, num_gates)\n",
    "    logp_qbit = calc_logp(logits_qbit, num_gates)\n",
    "\n",
    "    selected_logp_gate = calc_selected_logp(logp_gate, batch.onehot_igates)\n",
    "    selected_logp_qbit = calc_selected_logp(logp_qbit, batch.onehot_qubits)\n",
    "\n",
    "    selected_logp = (selected_logp_gate + selected_logp_qbit).sum(dim=-1)\n",
    "    \n",
    "    logp_best = (batch.onehot_ibests * selected_logp).sum(dim=-1)\n",
    "    logp_others = (selected_logp.sum(dim=-1) - logp_best) / (num_candidates - 1)\n",
    "    if detach:\n",
    "        logp_best = logp_best.detach()\n",
    "        logp_others = logp_others.detach()\n",
    "    return logp_best, logp_others\n",
    "\n",
    "calc_logps(policy, batch, num_candidates, num_gates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_dpo(logrp, logrp_ref, beta=0.5):\n",
    "    return -1 * nn.functional.logsigmoid(beta * (logrp - logrp_ref)).mean()\n",
    "\n",
    "def calc_loss_llh(logp_best):\n",
    "    return torch.exp(logp_best).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-5.8862, -5.9920, -6.6633, -6.6659], grad_fn=<SumBackward1>),\n",
       " tensor([-5.8862, -5.9920, -6.6633, -6.6659]))"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logp_best, logp_others = calc_logps(policy, batch, num_candidates, num_gates)\n",
    "logp_ref_best, logp_ref_others = calc_logps(policy_ref, batch, num_candidates, num_gates, detach=True)\n",
    "logp_best, logp_ref_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6931, grad_fn=<MulBackward0>),\n",
       " tensor(0.0020, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_dpo = calc_loss_dpo(logp_best - logp_others, logp_ref_best - logp_ref_others, beta=beta)\n",
    "loss_llh = calc_loss_llh(logp_best)\n",
    "loss_dpo, loss_llh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logrp = logp_best - logp_others\n",
    "logrp_ref = logp_ref_best - logp_ref_others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6931, 0.6931, 0.6931, 0.6931], grad_fn=<MulBackward0>) tensor([0.0028, 0.0025, 0.0013, 0.0013], grad_fn=<ExpBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss_dpo = -1 * nn.functional.logsigmoid(beta * (logp_best - logp_ref_best - logp_others + logp_ref_others))\n",
    "loss_llh = torch.exp(logp_best)\n",
    "print(loss_dpo, loss_llh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = Policy(dim_wavelet, num_qubits, num_gates)\n",
    "policy_ref = Policy(dim_wavelet, num_qubits, num_gates)\n",
    "policy_ref.load_state_dict(policy.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(policy.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before train step\n",
    "logits = policy(batch.states)\n",
    "logits_gate = logits[..., :policy.dim_gateinfo]\n",
    "logits_qbit = logits[..., policy.dim_gateinfo:]\n",
    "\n",
    "before = calc_logp(logits_gate, num_gates)[..., 0].detach().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calc loss here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:  1 loss:  0.693\n",
      "step:  2 loss:  0.688\n",
      "step:  3 loss:  0.682\n",
      "step:  4 loss:  0.678\n",
      "step:  5 loss:  0.673\n",
      "step:  6 loss:  0.668\n",
      "step:  7 loss:  0.663\n",
      "step:  8 loss:  0.659\n",
      "step:  9 loss:  0.654\n",
      "step: 10 loss:  0.650\n",
      "step: 11 loss:  0.646\n",
      "step: 12 loss:  0.642\n",
      "step: 13 loss:  0.637\n",
      "step: 14 loss:  0.633\n",
      "step: 15 loss:  0.629\n",
      "step: 16 loss:  0.625\n",
      "step: 17 loss:  0.621\n",
      "step: 18 loss:  0.617\n",
      "step: 19 loss:  0.613\n",
      "step: 20 loss:  0.609\n",
      "step: 21 loss:  0.605\n",
      "step: 22 loss:  0.601\n",
      "step: 23 loss:  0.597\n",
      "step: 24 loss:  0.593\n",
      "step: 25 loss:  0.589\n",
      "step: 26 loss:  0.585\n",
      "step: 27 loss:  0.580\n",
      "step: 28 loss:  0.576\n",
      "step: 29 loss:  0.571\n",
      "step: 30 loss:  0.566\n",
      "step: 31 loss:  0.562\n",
      "step: 32 loss:  0.557\n",
      "step: 33 loss:  0.551\n",
      "step: 34 loss:  0.546\n",
      "step: 35 loss:  0.541\n",
      "step: 36 loss:  0.535\n",
      "step: 37 loss:  0.529\n",
      "step: 38 loss:  0.523\n",
      "step: 39 loss:  0.517\n",
      "step: 40 loss:  0.510\n",
      "step: 41 loss:  0.504\n",
      "step: 42 loss:  0.497\n",
      "step: 43 loss:  0.491\n",
      "step: 44 loss:  0.484\n",
      "step: 45 loss:  0.477\n",
      "step: 46 loss:  0.470\n",
      "step: 47 loss:  0.463\n",
      "step: 48 loss:  0.456\n",
      "step: 49 loss:  0.448\n",
      "step: 50 loss:  0.441\n"
     ]
    }
   ],
   "source": [
    "for step in range(50):\n",
    "    # prediction\n",
    "    logp_best, logp_others = calc_logps(policy, batch, num_candidates, num_gates)\n",
    "    logp_ref_best, logp_ref_others = calc_logps(policy_ref, batch, num_candidates, num_gates, detach=True)\n",
    "\n",
    "    # losses\n",
    "    loss_dpo = calc_loss_dpo(logp_best - logp_others, logp_ref_best - logp_ref_others, beta=beta)\n",
    "    loss_llh = calc_loss_llh(logp_best)\n",
    "    loss = loss_dpo + 0 * loss_llh\n",
    "    print(f\"step:{step+1:>3d} loss: {loss_dpo.item():6.3f}\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after train step\n",
    "logits = policy(batch.states)\n",
    "logits_gate = logits[..., :policy.dim_gateinfo]\n",
    "logits_qbit = logits[..., policy.dim_gateinfo:]\n",
    "\n",
    "after = calc_logp(logits_gate, num_gates)[..., 0].detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.4901234 , -0.46423495, -0.3027004 ],\n",
       "        [-0.63642216, -0.5208156 , -0.26988602],\n",
       "        [-0.6360792 , -0.5051565 , -0.28410172],\n",
       "        [-0.73366046, -0.61706424, -0.39302683]], dtype=float32),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after - before, batch.best_indices[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1430, 0.2282, 0.2980, 0.3308],\n",
       "        [0.1494, 0.3352, 0.2723, 0.2431],\n",
       "        [0.1406, 0.1072, 0.4759, 0.2763]], grad_fn=<ExpBackward0>)"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = policy(batch.states)\n",
    "logits_gate = logits[..., :policy.dim_gateinfo]\n",
    "logits_qbit = logits[..., policy.dim_gateinfo:]\n",
    "torch.exp(calc_logp(logits_gate, num_gates)[0, ...])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lb-qml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

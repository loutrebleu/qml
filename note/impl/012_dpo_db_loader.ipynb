{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n",
    "from collections import namedtuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qml.model.gate import Gateset\n",
    "from qml.model.unit import UnitManager, Unit\n",
    "from qml.tools.random import XRandomGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_db_filename = \"dpo_databsae.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPOBatch:\n",
    "\n",
    "    def __init__(self, wseries, best_unit, other_units):\n",
    "        self.wseries = wseries\n",
    "        self.best_unit = best_unit\n",
    "        self.other_units = other_units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPOData(wseries=array([-0.26506404,  0.03155852, -0.4379742 ]), gate_indices=[[0, 1, 0], [3, 2, 1], [0, 0, 2], [3, 2, 1], [0, 2, 3]], qubits=[[1, 0, 1], [1, 1, 1], [0, 1, 0], [1, 1, 0], [1, 0, 1]], losses=array([0.05769153, 0.37874371, 0.27544483, 0.07399594, 0.35288897]))"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DPODataset:\n",
    "\n",
    "    def __init__(self, db_filename: str, num_qubits: int, dim_wavelet: int = 4):\n",
    "        self.db_filename = db_filename\n",
    "        self.num_qubits = num_qubits\n",
    "        self.dim_wavelet = dim_wavelet\n",
    "\n",
    "        self.gateset = Gateset.set_num_qubits(num_qubits)\n",
    "\n",
    "        self.db = self.load_db_file()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        djson = self.db[index]\n",
    "        return DPODataDecoder.from_json(djson, self.gateset, self.dim_wavelet)\n",
    "    \n",
    "    def load_db_file(self):\n",
    "        with open(self.db_filename) as fp:\n",
    "            djsons = fp.readlines()        \n",
    "        return djsons\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self.db)\n",
    "\n",
    "\n",
    "dataset = DPODataset(dpo_db_filename, 2, 2)\n",
    "dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "DPOData = namedtuple(\"DPOData\", [\"wseries\", \"gindices\", \"qubits\", \"losses\"])\n",
    "\n",
    "class DPODataDecoder:\n",
    "\n",
    "    KEY_WSERIES = \"wseries\"\n",
    "    KEY_UNITS = \"units\"\n",
    "    KEY_UNITS_GATES = \"gates\"\n",
    "    KEY_UNITS_QUBITS = \"qubits\"\n",
    "    KEY_LOSSES = \"losses\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, djson: str, gateset: Gateset, dim_wavelet: int = 4):\n",
    "        gdict = {gate_name: idx for idx, gate_name in enumerate(gateset.keys())}\n",
    "        ddict = json.loads(djson)\n",
    "\n",
    "        # wseries\n",
    "        wseries = np.asarray(ddict[cls.KEY_WSERIES])\n",
    "        len_wseries = 2 ** dim_wavelet - 1\n",
    "        dwseries = wseries[:len_wseries]\n",
    "\n",
    "        # units\n",
    "        udicts = ddict[cls.KEY_UNITS]\n",
    "        # units/gate_indices\n",
    "        dginfices = [\n",
    "            [\n",
    "                gdict[ugate.upper()]\n",
    "                for ugate in udict[cls.KEY_UNITS_GATES]\n",
    "            ] for udict in udicts\n",
    "        ]\n",
    "        dqubits = [\n",
    "            udict[cls.KEY_UNITS_QUBITS]\n",
    "            for udict in udicts\n",
    "        ]\n",
    "\n",
    "        # losses\n",
    "        dlosses = np.asarray(ddict[cls.KEY_LOSSES])\n",
    "\n",
    "        return DPOData(dwseries, dginfices, dqubits, dlosses)\n",
    "    \n",
    "    @classmethod\n",
    "    def divide_best_and_others(cls, data: DPOData):\n",
    "        bgindices = data.gindices\n",
    "        bqubits = data.qubits\n",
    "        blosses = data.losses\n",
    "\n",
    "        bbest_indices = np.argmin(blosses, axis=1)\n",
    "\n",
    "        # collect best candidates\n",
    "        best_gindices = [\n",
    "            gindices[best_index]\n",
    "            for gindices, best_index in zip(bgindices, bbest_indices)\n",
    "        ]\n",
    "\n",
    "        best_qubits = [\n",
    "            qubits[best_index]\n",
    "            for qubits, best_index in zip(bqubits, bbest_indices)\n",
    "        ]\n",
    "\n",
    "        best_losses = np.min(blosses, axis=1)\n",
    "\n",
    "        best_data = DPOData(data.wseries, best_gindices, best_qubits, best_losses)\n",
    "\n",
    "        # collect others\n",
    "        others_ginfices = [\n",
    "            [gindex for idx, gindex in enumerate(gindices) if idx != best_index]\n",
    "            for gindices, best_index in zip(bgindices, bbest_indices)\n",
    "        ]\n",
    "\n",
    "        others_qubits = [\n",
    "            [qubit for idx, qubit in enumerate(qubits) if idx != best_index]\n",
    "            for qubits, best_index in zip(bqubits, bbest_indices)\n",
    "        ]\n",
    "\n",
    "        others_losses = [\n",
    "            [loss.item() for idx, loss in enumerate(losses) if idx != best_index]\n",
    "            for losses, best_index in zip(blosses, bbest_indices)\n",
    "        ]\n",
    "\n",
    "        others_data = DPOData(data.wseries, others_ginfices, others_qubits, others_losses)\n",
    "        \n",
    "        return best_data, others_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DPODataBatchDivided:\n",
    "\n",
    "    def __init__(self, batch_data: DPOData, nq: int, ngc: int):\n",
    "        self.data = batch_data\n",
    "        self.nq = nq\n",
    "        self.ngc = ngc\n",
    "    \n",
    "    @staticmethod\n",
    "    def as_onehot(indices, num_classes):\n",
    "        onehot = nn.functional.one_hot(indices, num_classes)\n",
    "        return onehot\n",
    "\n",
    "    @property\n",
    "    def np_gindices(self):\n",
    "        return np.asarray(self.data.gindices).astype(int)\n",
    "    \n",
    "    @property\n",
    "    def gindices(self):\n",
    "        return torch.from_numpy(self.np_gindices).float()\n",
    "    \n",
    "    @property\n",
    "    def onehot_gindices(self):\n",
    "        return self.as_onehot(self.gindices.long(), self.ngc)\n",
    "    \n",
    "    @property\n",
    "    def np_qubits(self):\n",
    "        return np.asarray(self.data.qubits).astype(int)\n",
    "    \n",
    "    @property\n",
    "    def qubits(self):\n",
    "        return torch.from_numpy(self.np_qubits).float()\n",
    "    \n",
    "    @property\n",
    "    def onehot_qubits(self):\n",
    "        return self.as_onehot(self.qubits.long(), self.nq)\n",
    "    \n",
    "    @property\n",
    "    def np_losses(self):\n",
    "        return np.asarray(self.data.losses).astype(float)\n",
    "    \n",
    "    @property\n",
    "    def losses(self):\n",
    "        return torch.from_numpy(self.np_losses).float()\n",
    "\n",
    "\n",
    "class DPODataBatch:\n",
    "\n",
    "    def __init__(self, batch_data: DPOData, num_qubits: int, num_gate_classes: int = None):\n",
    "        if num_gate_classes is None:\n",
    "            num_gate_classes = Gateset.set_num_qubits(num_qubits).size\n",
    "        self.num_qubits = num_qubits\n",
    "        self.num_gate_classes = num_gate_classes\n",
    "        self.data = data = batch_data\n",
    "        self.best_data = None\n",
    "        self.others_data = None\n",
    "        self._wseries = np.vstack(data.wseries)\n",
    "\n",
    "        self.encode(data)\n",
    "    \n",
    "    def encode(self, data):\n",
    "        best_data, others_data = DPODataDecoder.divide_best_and_others(data)\n",
    "        self.best_data = DPODataBatchDivided(best_data, self.num_qubits, self.num_gate_classes)\n",
    "        self.others_data = DPODataBatchDivided(others_data, self.num_qubits, self.num_gate_classes)\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def wserieses(self):\n",
    "        return torch.from_numpy(self._wseries).float()\n",
    "    \n",
    "    @property\n",
    "    def np_wserieses(self):\n",
    "        return self._wseries.copy()\n",
    "    \n",
    "    @property\n",
    "    def best(self):\n",
    "        return self.best_data\n",
    "    \n",
    "    @property\n",
    "    def others(self):\n",
    "        return self.others_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 4, 3, 2])\n",
      "tensor([[[[0, 1],\n",
      "          [1, 0],\n",
      "          [1, 0]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [1, 0],\n",
      "          [1, 0]],\n",
      "\n",
      "         [[1, 0],\n",
      "          [0, 1],\n",
      "          [1, 0]],\n",
      "\n",
      "         [[1, 0],\n",
      "          [1, 0],\n",
      "          [0, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 0],\n",
      "          [0, 1],\n",
      "          [0, 1]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [0, 1],\n",
      "          [0, 1]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [0, 1],\n",
      "          [0, 1]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [0, 1],\n",
      "          [1, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 1],\n",
      "          [0, 1],\n",
      "          [0, 1]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [1, 0],\n",
      "          [1, 0]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [0, 1],\n",
      "          [0, 1]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [1, 0],\n",
      "          [0, 1]]],\n",
      "\n",
      "\n",
      "        [[[1, 0],\n",
      "          [0, 1],\n",
      "          [1, 0]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [0, 1],\n",
      "          [0, 1]],\n",
      "\n",
      "         [[1, 0],\n",
      "          [0, 1],\n",
      "          [1, 0]],\n",
      "\n",
      "         [[1, 0],\n",
      "          [0, 1],\n",
      "          [1, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 1],\n",
      "          [1, 0],\n",
      "          [0, 1]],\n",
      "\n",
      "         [[1, 0],\n",
      "          [0, 1],\n",
      "          [1, 0]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [0, 1],\n",
      "          [1, 0]],\n",
      "\n",
      "         [[1, 0],\n",
      "          [1, 0],\n",
      "          [1, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 1],\n",
      "          [1, 0],\n",
      "          [0, 1]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [1, 0],\n",
      "          [1, 0]],\n",
      "\n",
      "         [[1, 0],\n",
      "          [0, 1],\n",
      "          [0, 1]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [0, 1],\n",
      "          [1, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 1],\n",
      "          [1, 0],\n",
      "          [1, 0]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [0, 1],\n",
      "          [0, 1]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [0, 1],\n",
      "          [0, 1]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [0, 1],\n",
      "          [1, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 1],\n",
      "          [1, 0],\n",
      "          [1, 0]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [0, 1],\n",
      "          [1, 0]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [0, 1],\n",
      "          [1, 0]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [0, 1],\n",
      "          [1, 0]]],\n",
      "\n",
      "\n",
      "        [[[1, 0],\n",
      "          [0, 1],\n",
      "          [1, 0]],\n",
      "\n",
      "         [[1, 0],\n",
      "          [1, 0],\n",
      "          [1, 0]],\n",
      "\n",
      "         [[1, 0],\n",
      "          [0, 1],\n",
      "          [0, 1]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [1, 0],\n",
      "          [1, 0]]],\n",
      "\n",
      "\n",
      "        [[[1, 0],\n",
      "          [1, 0],\n",
      "          [0, 1]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [1, 0],\n",
      "          [0, 1]],\n",
      "\n",
      "         [[0, 1],\n",
      "          [1, 0],\n",
      "          [1, 0]],\n",
      "\n",
      "         [[1, 0],\n",
      "          [1, 0],\n",
      "          [0, 1]]]])\n"
     ]
    }
   ],
   "source": [
    "class DPODataLoaderIter:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset: DPODataset,\n",
    "            batched_indices: list[list[int]],\n",
    "            num_qubits: int,\n",
    "            num_gate_classes: int,\n",
    "    ):\n",
    "        self.db = dataset\n",
    "        self.indices = batched_indices\n",
    "\n",
    "        self.nq = num_qubits\n",
    "        self.ngc = num_gate_classes\n",
    "\n",
    "        self.indices_iter = iter(batched_indices)\n",
    "    \n",
    "    def __next__(self):\n",
    "        idxs = next(self.indices_iter)\n",
    "        bdata = [self.db[idx] for idx in idxs]\n",
    "        bdata = DPOData(\n",
    "            [data.wseries for data in bdata],\n",
    "            [data.gindices for  data in bdata],\n",
    "            [data.qubits for  data in bdata],\n",
    "            [data.losses for  data in bdata],\n",
    "        )\n",
    "        return DPODataBatch(bdata, self.nq, self.ngc)\n",
    "\n",
    "class DPODataLoader:\n",
    "    \n",
    "    def __init__(self, dataset: DPODataset, num_qubits: int, batch_size: int, max_wavelet_dim: int = 4, seed: int = None):\n",
    "        self.rng = XRandomGenerator(seed)\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.num_qubits = num_qubits\n",
    "        self.num_gate_classes = Gateset.set_num_qubits(num_qubits).size\n",
    "        self.max_wavelet_dim = max_wavelet_dim\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return int(np.ceil(self.dataset.size / self.batch_size))\n",
    "    \n",
    "    def __iter__(self):\n",
    "        indices = np.arange(self.dataset.size).astype(int)\n",
    "        indices = self.rng.permutation(indices)\n",
    "        batched_indices = indices.reshape((self.size, self.batch_size))\n",
    "        return DPODataLoaderIter(self.dataset, batched_indices, self.num_qubits, self.num_gate_classes)\n",
    "\n",
    "\n",
    "\n",
    "loader = DPODataLoader(dataset, 2, 10)\n",
    "for batch in loader:\n",
    "    print(batch.others.onehot_qubits.shape)\n",
    "    print(batch.others.onehot_qubits)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lb-qml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

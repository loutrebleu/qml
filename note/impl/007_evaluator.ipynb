{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from numpy.typing import NDArray\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_aer import AerSimulator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qml.model.gate import Gateset\n",
    "from qml.model.unit import Unit, UnitManager\n",
    "from qml.model.encoding import EncodingUnit, EncodingUnitManager\n",
    "from qml.model.model import Model\n",
    "from qml.tools.dataset import Dataset\n",
    "from qml.tools.dataloader import DataLoader\n",
    "from qml.tools.typing import Vector\n",
    "from qml.tools.random import XRandomGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nq = 2\n",
    "ng = 3\n",
    "nx = 1\n",
    "ny = 1\n",
    "\n",
    "# dataset\n",
    "train_db_size = 10\n",
    "validate_db_size = 10\n",
    "# loader\n",
    "batch_size = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_func = lambda x: np.sin(2 * x)\n",
    "rng = XRandomGenerator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalResult:\n",
    "\n",
    "    def __init__(self, xs: NDArray, ys: NDArray) -> None:\n",
    "        self._xs = np.asarray(xs)\n",
    "        self._ys = np.asarray(ys)\n",
    "    \n",
    "    @property\n",
    "    def xs(self):\n",
    "        return self._xs.copy()\n",
    "\n",
    "    @property\n",
    "    def ys(self):\n",
    "        return self._ys.copy()\n",
    "\n",
    "\n",
    "class Evaluator:\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset: Dataset,\n",
    "            model: Model = None,\n",
    "            batch_size: int = None,\n",
    "            shots: int = 50,\n",
    "            seed: int = None,\n",
    "            raise_iteration_error: bool = True,\n",
    "    ):\n",
    "        self._rng = XRandomGenerator(seed)\n",
    "        self.dataset = dataset\n",
    "        self.model = model\n",
    "        self.batch_size = batch_size = batch_size if batch_size is not None else len(dataset)\n",
    "        self.shuffle = False\n",
    "        self.shots = shots\n",
    "\n",
    "        self._loader = DataLoader.from_dataset(\n",
    "            dataset, batch_size, shuffle=self.shuffle, seed=self._rng.new_seed()\n",
    "        )\n",
    "        self._loader_iter = None\n",
    "        self._raise_iteration_error = raise_iteration_error\n",
    "    \n",
    "    def __call__(\n",
    "            self,\n",
    "            params: NDArray = None,\n",
    "            model: Model = None\n",
    "    ) -> EvalResult:\n",
    "        if model is None:\n",
    "            model = self.model\n",
    "            \n",
    "        if self._loader_iter is None:\n",
    "            self._loader_iter = iter(self._loader)\n",
    "        \n",
    "        try:\n",
    "            xs, ys = next(self._loader_iter)\n",
    "        except StopIteration:\n",
    "            if self._raise_iteration_error:\n",
    "                raise StopIteration()\n",
    "            self._loader_iter = iter(self._loader)\n",
    "            xs, ys = next(self._loader_iter)\n",
    "        \n",
    "        return self.evaluate(\n",
    "            model, params, xs, ys, shots=self.shots\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def evaluate(\n",
    "        cls,\n",
    "        model: Model,\n",
    "        params: NDArray,\n",
    "        xs: NDArray,\n",
    "        ys: NDArray,\n",
    "        shots: int = None,\n",
    "    ):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.37255812 -0.58267834  0.24407353  0.38630485 -1.15512685]\n",
      "[ 0.65587139 -1.67636126  0.26893421  0.31957937  0.37514308]\n"
     ]
    }
   ],
   "source": [
    "class ErrorEvalResult(EvalResult):\n",
    "\n",
    "    def __init__(self, errors: NDArray, xs: NDArray, ys: NDArray):\n",
    "        super().__init__(xs, ys)\n",
    "        self._es = np.asarray(errors)\n",
    "    \n",
    "    @property\n",
    "    def es(self):\n",
    "        return self._es.copy()\n",
    "    \n",
    "    @property\n",
    "    def errors(self):\n",
    "        return self.es\n",
    "\n",
    "\n",
    "class ErrorEvaluator(Evaluator):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset: Dataset,\n",
    "            model: Model = None,\n",
    "            batch_size: int = None,\n",
    "            shots: int = 50,\n",
    "            seed: int = None\n",
    "    ):\n",
    "        super().__init__(dataset, model, batch_size, shots, seed)\n",
    "    \n",
    "    @classmethod\n",
    "    def evaluate(\n",
    "            cls,\n",
    "            model: Model,\n",
    "            params: NDArray,\n",
    "            xs: NDArray,\n",
    "            ys: NDArray,\n",
    "            shots: int = None,\n",
    "    ):\n",
    "        ps = np.asarray([\n",
    "            model.forward(x, params=params, shots=shots)\n",
    "            for x in xs\n",
    "        ])\n",
    "        es = ys - ps\n",
    "        res = ErrorEvalResult(es, xs, ys)\n",
    "        return res\n",
    "\n",
    "\n",
    "xs = rng.uniform(-1, 1, train_db_size)\n",
    "ys = target_func(xs)\n",
    "dataset = Dataset(xs, ys)\n",
    "\n",
    "uman = UnitManager(nq, ng)\n",
    "model = Model(\n",
    "    nq, ny,\n",
    "    EncodingUnitManager.AngleEncoding(nx, nq, repeat=True),\n",
    "    uman.generate_random_unit(),\n",
    ")\n",
    "\n",
    "evl = ErrorEvaluator(dataset, model, 5)\n",
    "res = evl()\n",
    "print(res.es)\n",
    "res = evl()\n",
    "print(res.es)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6841242493248634\n",
      "1.1560157476013377\n"
     ]
    }
   ],
   "source": [
    "class MSEEvalResult(EvalResult):\n",
    "\n",
    "    def __init__(self, loss: float, xs: NDArray, ys: NDArray):\n",
    "        super().__init__(xs, ys)\n",
    "        self._loss = np.asarray(loss)\n",
    "    \n",
    "    @property\n",
    "    def loss(self):\n",
    "        return self._loss.copy()\n",
    "\n",
    "\n",
    "class MSEEvaluator(Evaluator):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset: Dataset,\n",
    "            model: Model = None,\n",
    "            batch_size: int = None,\n",
    "            shots: int = 50,\n",
    "            seed: int = None\n",
    "    ):\n",
    "        super().__init__(dataset, model, batch_size, shots, seed)\n",
    "    \n",
    "    @classmethod\n",
    "    def evaluate(\n",
    "            cls,\n",
    "            model: Model,\n",
    "            params: NDArray,\n",
    "            xs: NDArray,\n",
    "            ys: NDArray,\n",
    "            shots: int = None,\n",
    "    ):\n",
    "        res = ErrorEvaluator.evaluate(model, params, xs, ys, shots)\n",
    "        loss = np.square(res.es).mean()\n",
    "        return MSEEvalResult(loss, xs, ys)\n",
    "\n",
    "\n",
    "xs = rng.uniform(-1, 1, train_db_size)\n",
    "ys = target_func(xs)\n",
    "dataset = Dataset(xs, ys)\n",
    "\n",
    "uman = UnitManager(nq, ng)\n",
    "model = Model(\n",
    "    nq, ny,\n",
    "    EncodingUnitManager.AngleEncoding(nx, nq, repeat=True),\n",
    "    uman.generate_random_unit(),\n",
    ")\n",
    "\n",
    "evl = MSEEvaluator(dataset, model, 5)\n",
    "res = evl()\n",
    "print(res.loss)\n",
    "res = evl()\n",
    "print(res.loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientEvalResult(ErrorEvalResult):\n",
    "\n",
    "    def __init__(self, grads: NDArray, errors: NDArray, xs: NDArray, ys: NDArray) -> None:\n",
    "        super().__init__(errors, xs, ys)\n",
    "        self._grads = grads\n",
    "\n",
    "    @property\n",
    "    def gradients(self):\n",
    "        return self._grads.copy()\n",
    "    \n",
    "    @property\n",
    "    def grads(self):\n",
    "        return self.gradients\n",
    "\n",
    "    @property\n",
    "    def loss(self):\n",
    "        return np.square(self.es).mean()\n",
    "\n",
    "\n",
    "\n",
    "class GradientEvaluator(Evaluator):\n",
    "\n",
    "    demi_pi = np.pi / 2\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            dataset: Dataset,\n",
    "            model: Model = None,\n",
    "            batch_size: int = None,\n",
    "            shots: int = 50,\n",
    "            seed: int = None\n",
    "    ):\n",
    "        super().__init__(dataset, model, batch_size, shots, seed)\n",
    "    \n",
    "    @classmethod\n",
    "    def evaluate(\n",
    "            cls,\n",
    "            model: Model,\n",
    "            params: NDArray,\n",
    "            xs: NDArray,\n",
    "            ys: NDArray,\n",
    "            shots: int = None,\n",
    "    ):\n",
    "        grads = np.asarray([\n",
    "            cls.calc_gradient_idx_(model, params, x, shots=shots)\n",
    "            for x in xs\n",
    "        ])\n",
    "        eres = ErrorEvaluator.evaluate(model, params, xs, ys, shots=shots)\n",
    "        return GradientEvalResult(grads, eres.errors, xs, ys)\n",
    "    \n",
    "\n",
    "    @classmethod\n",
    "    def calc_gradient_idx_(\n",
    "            cls,\n",
    "            model: Model,\n",
    "            params: NDArray,\n",
    "            x: NDArray,\n",
    "            shots: int = None,\n",
    "    ):\n",
    "        if params is None:\n",
    "            params = model.trainable_parameters\n",
    "        trainable_params = params.copy()\n",
    "        tp_shapes = [len(tp) for tp in trainable_params]\n",
    "        tp_shapes.insert(0, 0)\n",
    "        tp_shape_idxs = np.cumsum(tp_shapes)\n",
    "\n",
    "        trainable_params = np.hstack(trainable_params)\n",
    "\n",
    "        def deflatten(flattened):\n",
    "            return [\n",
    "                flattened[idx_de:idx_to]\n",
    "                for idx_de, idx_to\n",
    "                in zip(tp_shape_idxs[:-1], tp_shape_idxs[1:])\n",
    "            ]\n",
    "        \n",
    "        def calc_gradient_idx(idx):\n",
    "            shifted_pos = trainable_params.copy()\n",
    "            shifted_neg = trainable_params.copy()\n",
    "            shifted_pos[idx] = trainable_params[idx] + cls.demi_pi\n",
    "            shifted_neg[idx] = trainable_params[idx] - cls.demi_pi\n",
    "\n",
    "            predict_pos = model.forward(\n",
    "                x,\n",
    "                params=deflatten(shifted_pos),\n",
    "                shots=shots,\n",
    "            )\n",
    "            predict_neg = model.forward(\n",
    "                x,\n",
    "                params=deflatten(shifted_neg),\n",
    "                shots=shots,\n",
    "            )\n",
    "            grad = (predict_pos - predict_neg) / 2\n",
    "            return grad\n",
    "        \n",
    "        grads = np.asarray([\n",
    "            calc_gradient_idx(idx)\n",
    "            for idx in range(len(trainable_params))\n",
    "        ])\n",
    "        return grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = rng.uniform(-1, 1, train_db_size)\n",
    "ys = target_func(xs)\n",
    "dataset = Dataset(xs, ys)\n",
    "\n",
    "uman = UnitManager(nq, ng)\n",
    "model = Model(\n",
    "    nq, ny,\n",
    "    EncodingUnitManager.AngleEncoding(nx, nq, repeat=True),\n",
    "    uman.generate_random_unit(),\n",
    "    uman.generate_random_unit(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3)\n",
      "(10, 3)\n"
     ]
    }
   ],
   "source": [
    "evfunc = GradientEvaluator(dataset, model, 5)\n",
    "res = evfunc()\n",
    "print(res.gradients.shape)\n",
    "res = evfunc()\n",
    "print(res.gradients.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wavelet:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_pattern_applied_func(self, a: float, b: float) -> Callable:\n",
    "        pass\n",
    "\n",
    "    def calc_wavelet_params(self, dim):\n",
    "        return sum([\n",
    "            [\n",
    "                (a, b)\n",
    "                for b in np.arange(-1, 1, a)\n",
    "            ]\n",
    "            for a in 2 / 2 ** np.arange(dim)\n",
    "        ], [])\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_wavelet_range(wavelet_param):\n",
    "        a, b = wavelet_param\n",
    "        return [b, a + b]\n",
    "\n",
    "\n",
    "class Haar(Wavelet):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_pattern_applied_func(self, a: float, b: float, xs) -> Callable:\n",
    "        shifted_xs = (xs - b) / a\n",
    "        yneg = np.where((-1 <= shifted_xs) & (shifted_xs < 0), -1, 0)\n",
    "        ypos = np.where((0 <= shifted_xs) & (shifted_xs < 1), 1, 0)\n",
    "        return (yneg + ypos) / np.sqrt(a)\n",
    "\n",
    "\n",
    "class WaveletTransform:\n",
    "\n",
    "    def __init__(self, wavelet: Wavelet) -> None:\n",
    "        self._wavelet = wavelet\n",
    "    \n",
    "    def transform(self, xs, ys, dim=4):\n",
    "        xs = np.asarray(xs)\n",
    "        ys = np.asarray(ys)\n",
    "        wparams = self.generate_wavelet_params(dim)\n",
    "        powers = np.asarray([\n",
    "            np.mean(\n",
    "                self._wavelet.get_pattern_applied_func(*wparam, xs) * ys\n",
    "            )\n",
    "            for wparam in wparams\n",
    "        ])\n",
    "        return powers\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_wavelet_params(dim):\n",
    "        return np.asarray(sum([\n",
    "            [\n",
    "                (a, b)\n",
    "                for b in np.arange(-1, 1, a)\n",
    "            ]\n",
    "            for a in 2 / 2 ** np.arange(dim)\n",
    "        ], []))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.40126696 -0.61804238  0.66860759 -0.51635187  0.15865983  0.29343329\n",
      "  0.2000275  -0.35872607 -0.01277968  0.06935184  0.09845489  0.20369903\n",
      " -0.0908756   0.14077148  0.09221423]\n",
      "[-0.37581112 -0.57804238  0.62460759 -0.47675389  0.13603241  0.28211959\n",
      "  0.18305694 -0.31872607 -0.03677968  0.07735184  0.07445489  0.20369903\n",
      " -0.0828756   0.13277148  0.07621423]\n"
     ]
    }
   ],
   "source": [
    "class WaveletEvalResult(EvalResult):\n",
    "\n",
    "    def __init__(self, errors: NDArray, powers: NDArray, xs: NDArray, ys: NDArray):\n",
    "        super().__init__(xs, ys)\n",
    "        self._es = np.asarray(errors)\n",
    "        self._ps = np.asarray(powers)\n",
    "    \n",
    "    @property\n",
    "    def es(self):\n",
    "        return self._es.copy()\n",
    "    \n",
    "    @property\n",
    "    def errors(self):\n",
    "        return self.es\n",
    "    \n",
    "    @property\n",
    "    def ps(self):\n",
    "        return self._ps.copy()\n",
    "    \n",
    "    @property\n",
    "    def powers(self):\n",
    "        return self.ps\n",
    "\n",
    "\n",
    "class WaveletEvaluator(Evaluator):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            wavelet: Wavelet,\n",
    "            dataset: Dataset,\n",
    "            model: Model = None,\n",
    "            wavelet_dim: int = 4,\n",
    "            batch_size: int = None,\n",
    "            shots: int = 50,\n",
    "            seed: int = None\n",
    "    ):\n",
    "        super().__init__(dataset, model, batch_size, shots, seed)\n",
    "        self._wavelet = wavelet\n",
    "        self._wtrans = WaveletTransform(wavelet)\n",
    "        self._wdim = wavelet_dim\n",
    "    \n",
    "    def __call__(\n",
    "            self,\n",
    "            params: NDArray = None,\n",
    "            model: Model = None\n",
    "    ) -> EvalResult:\n",
    "        if model is None:\n",
    "            model = self.model\n",
    "        return self.evaluate(\n",
    "            self._wtrans, self._wdim, model, params, self.dataset.xs, self.dataset.ys, shots=self.shots\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def evaluate(\n",
    "            cls,\n",
    "            wtrans: WaveletTransform,\n",
    "            wdim: int,\n",
    "            model: Model,\n",
    "            params: NDArray,\n",
    "            xs: NDArray,\n",
    "            ys: NDArray,\n",
    "            shots: int = None,\n",
    "    ):\n",
    "        eres = ErrorEvaluator.evaluate(model, params, xs, ys, shots=shots)\n",
    "        powers = wtrans.transform(xs, eres.errors, dim=wdim)\n",
    "        return WaveletEvalResult(eres.errors, powers, xs, ys)\n",
    "\n",
    "\n",
    "eval = WaveletEvaluator(Haar(), dataset, model, batch_size=5)\n",
    "res = eval()\n",
    "print(res.powers)\n",
    "res = eval()\n",
    "print(res.powers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lb-qml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

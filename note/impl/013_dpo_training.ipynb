{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qml.model.gate import Gateset\n",
    "from qml.db import dpo as xdpo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# circuit\n",
    "num_qubits = 2\n",
    "num_gates = 3\n",
    "\n",
    "# dataset\n",
    "db_filename = \"dpo_databsae.txt\"\n",
    "batch_size = 10\n",
    "dim_wavelet = 4\n",
    "\n",
    "# model\n",
    "dim_hiddens = [32, 32]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            dim_wavelet: int,\n",
    "            num_qubits: int,\n",
    "            num_gates: int,\n",
    "            dim_hiddens: list[int]\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.nq = num_qubits\n",
    "        self.ng = num_gates\n",
    "        self.gset = gset = Gateset.set_num_qubits(num_qubits)\n",
    "\n",
    "        self.dim_gindices = gset.size * self.ng\n",
    "        self.dim_qubits = self.ng * self.nq\n",
    "        self.dim_output = dim_output = self.dim_gindices + self.dim_qubits\n",
    "        self.dim_input = dim_input = 2 ** dim_wavelet - 1\n",
    "\n",
    "        dim_units = dim_hiddens.copy()\n",
    "        dim_units.append(dim_output)\n",
    "        dim_units.insert(0, dim_input)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            *sum([\n",
    "                self.build_layer(din, dout, activation=(l < len(dim_hiddens)))\n",
    "                for l, din, dout\n",
    "                in zip(range(len(dim_units)+1), dim_units[:-1], dim_units[1:])\n",
    "            ], [])\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def build_layer(din, dout, activation=True):\n",
    "        layer = [nn.Linear(din, dout)]\n",
    "        if activation:\n",
    "            layer.append(nn.ReLU())\n",
    "        return layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feat = self.net(x)\n",
    "        return feat\n",
    "    \n",
    "    def as_logps(self, logits):\n",
    "        print(logits.shape)\n",
    "        logits_gate = logits[..., :self.dim_gindices]\n",
    "        logits_qbit = logits[..., self.dim_gindices:]\n",
    "        logps_gate = nn.functional.log_softmax(logits_gate)\n",
    "        logps_qbit = nn.functional.log_softmax(logits_qbit)\n",
    "        return logps_gate, logps_qbit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xdpo.DPODataset(db_filename, num_qubits, dim_wavelet)\n",
    "loader = xdpo.DPODataLoader(dataset, num_qubits, batch_size, dim_wavelet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = Policy(dim_wavelet, num_qubits, num_gates, dim_hiddens)\n",
    "policy_ref = Policy(dim_wavelet, num_qubits, num_gates, dim_hiddens)\n",
    "policy_ref.load_state_dict(policy.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selected_logps(logits, onehot):\n",
    "    logps = nn.functional.log_softmax(logits, dim=-1)\n",
    "    selected_logps = (logps * onehot).sum(dim=-1)\n",
    "    return selected_logps\n",
    "\n",
    "def calc_logps(policy, batch):\n",
    "    logits = policy(batch.wserieses)\n",
    "\n",
    "    logits_gate = logits[..., :policy.dim_gindices].view(batch.best.onehot_gindices.shape)\n",
    "    logits_qbit = logits[..., policy.dim_gindices:].view(batch.best.onehot_qubits.shape)\n",
    "\n",
    "    logps_best = selected_logps(logits_gate, batch.best.onehot_gindices) + selected_logps(logits_qbit, batch.best.onehot_qubits)\n",
    "    logps_best = logps_best.sum(dim=-1)\n",
    "    logps_others = selected_logps(logits_gate, batch.others.onehot_gindices) + selected_logps(logits_qbit, batch.others.onehot_qubits)\n",
    "    logps_others = logps_others.sum(dim=-1)\n",
    "    \n",
    "    return logps_best, logps_others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_dpo(logrp, logrp_ref, beta=0.5):\n",
    "    return -1 * nn.functional.logsigmoid(beta * (logrp - logrp_ref)).mean()\n",
    "\n",
    "def calc_loss_llh(logp_best):\n",
    "    return torch.exp(logp_best).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6931, grad_fn=<MulBackward0>) tensor(0.0022, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for batch in loader:\n",
    "    logps_best, logps_others = calc_logps(policy, batch)\n",
    "    logps_ref_best, logps_ref_others = calc_logps(policy_ref, batch)\n",
    "\n",
    "    loss_dpo = calc_loss_dpo(\n",
    "        logps_best - logps_others,\n",
    "        logps_ref_best - logps_ref_others,\n",
    "    )\n",
    "    loss_llh = calc_loss_llh(logps_best)\n",
    "    print(loss_dpo, loss_llh)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lb-qml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
